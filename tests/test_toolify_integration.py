"""
æµ‹è¯• Toolify å·¥å…·è°ƒç”¨åŠŸèƒ½é›†æˆ
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from openai import OpenAI

# æµ‹è¯•å·¥å…·å®šä¹‰
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½",
                        "default": "celsius"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯"
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "æœ€å¤§ç»“æœæ•°é‡",
                        "default": 5,
                        "minimum": 1,
                        "maximum": 20
                    }
                },
                "required": ["query"]
            }
        }
    }
]


def test_non_stream_with_tools():
    """æµ‹è¯•éæµå¼è¯·æ±‚ä¸å·¥å…·è°ƒç”¨"""
    print("=" * 60)
    print("æµ‹è¯• 1: éæµå¼è¯·æ±‚ + å·¥å…·è°ƒç”¨")
    print("=" * 60)
    
    client = OpenAI(
        base_url="http://localhost:8080/v1",
        api_key="sk-123456"
    )
    
    try:
        response = client.chat.completions.create(
            model="GLM-4.5",
            messages=[
                {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
            ],
            tools=tools,
            tool_choice="auto"
        )
        
        print(f"\nâœ… è¯·æ±‚æˆåŠŸï¼")
        print(f"Finish reason: {response.choices[0].finish_reason}")
        
        if response.choices[0].message.tool_calls:
            print(f"\nğŸ”§ æ£€æµ‹åˆ° {len(response.choices[0].message.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for tool_call in response.choices[0].message.tool_calls:
                print(f"  - ID: {tool_call.id}")
                print(f"  - å·¥å…·: {tool_call.function.name}")
                print(f"  - å‚æ•°: {tool_call.function.arguments}")
        else:
            print(f"\nğŸ“ æ™®é€šå›å¤: {response.choices[0].message.content}")
        
        print(f"\nä½¿ç”¨æƒ…å†µ:")
        print(f"  - è¾“å…¥ tokens: {response.usage.prompt_tokens}")
        print(f"  - è¾“å‡º tokens: {response.usage.completion_tokens}")
        print(f"  - æ€»è®¡ tokens: {response.usage.total_tokens}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def test_stream_with_tools():
    """æµ‹è¯•æµå¼è¯·æ±‚ä¸å·¥å…·è°ƒç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æµå¼è¯·æ±‚ + å·¥å…·è°ƒç”¨")
    print("=" * 60)
    
    client = OpenAI(
        base_url="http://localhost:8080/v1",
        api_key="sk-123456"
    )
    
    try:
        stream = client.chat.completions.create(
            model="GLM-4.5",
            messages=[
                {"role": "user", "content": "å¸®æˆ‘æœç´¢Pythonæ•™ç¨‹"}
            ],
            tools=tools,
            stream=True
        )
        
        print(f"\nâœ… å¼€å§‹æ¥æ”¶æµå¼å“åº”...")
        has_tool_calls = False
        content_parts = []
        
        for chunk in stream:
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                
                if delta.content:
                    content_parts.append(delta.content)
                    print(delta.content, end="", flush=True)
                
                if delta.tool_calls:
                    has_tool_calls = True
                    print(f"\n\nğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨:")
                    for tool_call in delta.tool_calls:
                        if tool_call.function:
                            print(f"  - å·¥å…·: {tool_call.function.name}")
                            print(f"  - å‚æ•°: {tool_call.function.arguments}")
        
        if not has_tool_calls and content_parts:
            print(f"\n\nğŸ“ å®Œæ•´å†…å®¹: {''.join(content_parts)}")
        
        print(f"\nâœ… æµå¼å“åº”å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def test_without_tools():
    """æµ‹è¯•ä¸å¸¦å·¥å…·çš„æ™®é€šè¯·æ±‚"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: æ™®é€šè¯·æ±‚ï¼ˆä¸å¸¦å·¥å…·ï¼‰")
    print("=" * 60)
    
    client = OpenAI(
        base_url="http://localhost:8080/v1",
        api_key="sk-123456"
    )
    
    try:
        response = client.chat.completions.create(
            model="GLM-4.5",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
            ]
        )
        
        print(f"\nâœ… è¯·æ±‚æˆåŠŸï¼")
        print(f"Finish reason: {response.choices[0].finish_reason}")
        print(f"å›å¤: {response.choices[0].message.content}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def test_tool_choice_none():
    """æµ‹è¯• tool_choice=none"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: tool_choice=noneï¼ˆç¦æ­¢ä½¿ç”¨å·¥å…·ï¼‰")
    print("=" * 60)
    
    client = OpenAI(
        base_url="http://localhost:8080/v1",
        api_key="sk-123456"
    )
    
    try:
        response = client.chat.completions.create(
            model="GLM-4.5",
            messages=[
                {"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}
            ],
            tools=tools,
            tool_choice="none"  # æ˜ç¡®ç¦æ­¢ä½¿ç”¨å·¥å…·
        )
        
        print(f"\nâœ… è¯·æ±‚æˆåŠŸï¼")
        print(f"Finish reason: {response.choices[0].finish_reason}")
        
        if response.choices[0].message.tool_calls:
            print(f"âŒ é”™è¯¯ï¼šä¸åº”è¯¥æœ‰å·¥å…·è°ƒç”¨ï¼")
        else:
            print(f"âœ… æ­£ç¡®ï¼šæ²¡æœ‰å·¥å…·è°ƒç”¨")
            print(f"å›å¤: {response.choices[0].message.content[:200]}...")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("\n" + "ğŸš€" * 30)
    print("Toolify å·¥å…·è°ƒç”¨åŠŸèƒ½é›†æˆæµ‹è¯•")
    print("ğŸš€" * 30)
    print("\nâš ï¸  è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼špython main.py")
    print("âš ï¸  è¯·ç¡®ä¿ ENABLE_TOOLIFY=true å·²è®¾ç½®")
    
    input("\næŒ‰ Enter é”®å¼€å§‹æµ‹è¯•...")
    
    # æ‰§è¡Œæµ‹è¯•
    test_non_stream_with_tools()
    test_stream_with_tools()
    test_without_tools()
    test_tool_choice_none()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)

