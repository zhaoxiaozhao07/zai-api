#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¹¶å‘æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•OpenAIå…¼å®¹APIæœåŠ¡å™¨çš„å¹¶å‘å¤„ç†èƒ½åŠ›
"""

import asyncio
import httpx
import json
import time
import sys
import io
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import statistics

# Windowsç¼–ç å¤„ç†
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# é…ç½®
API_BASE_URL = "http://localhost:8080"
API_KEY = "sk-123456"

# æµ‹è¯•æ¶ˆæ¯æ¨¡æ¿
TEST_MESSAGES = [
    {
        "role": "user",
        "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
    },
    {
        "role": "user",
        "content": "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"
    },
    {
        "role": "user",
        "content": "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚"
    },
    {
        "role": "user",
        "content": "ä»€ä¹ˆæ˜¯RESTful APIï¼Ÿ"
    },
    {
        "role": "user",
        "content": "è¯·åˆ—ä¸¾3ä¸ªå¸¸ç”¨çš„æ•°æ®ç»“æ„ã€‚"
    },
]


@dataclass
class RequestResult:
    """è¯·æ±‚ç»“æœæ•°æ®ç±»"""
    request_id: int
    success: bool
    status_code: Optional[int]
    duration: float  # å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    error_message: Optional[str] = None
    response_data: Optional[Dict[str, Any]] = None
    tokens_used: Optional[int] = None


def print_section(title: str, width: int = 100):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * width)
    print(f" {title} ".center(width))
    print("=" * width)


async def send_single_request(
    client: httpx.AsyncClient,
    request_id: int,
    model: str = "glm-4.5",
    stream: bool = False,
    message_index: int = 0
) -> RequestResult:
    """
    å‘é€å•ä¸ªè¯·æ±‚
    
    Args:
        client: httpxå¼‚æ­¥å®¢æˆ·ç«¯
        request_id: è¯·æ±‚ID
        model: æ¨¡å‹åç§°
        stream: æ˜¯å¦æµå¼
        message_index: æ¶ˆæ¯ç´¢å¼•
    
    Returns:
        RequestResult: è¯·æ±‚ç»“æœ
    """
    url = f"{API_BASE_URL}/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    # é€‰æ‹©æµ‹è¯•æ¶ˆæ¯
    messages = [TEST_MESSAGES[message_index % len(TEST_MESSAGES)]]
    
    payload = {
        "model": model,
        "messages": messages,
        "stream": stream,
        "temperature": 0.7,
        "max_tokens": 200
    }
    
    start_time = time.time()
    
    try:
        if not stream:
            # éæµå¼è¯·æ±‚
            response = await client.post(url, json=payload, headers=headers)
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                tokens = data.get("usage", {}).get("total_tokens", 0)
                
                return RequestResult(
                    request_id=request_id,
                    success=True,
                    status_code=response.status_code,
                    duration=duration,
                    response_data=data,
                    tokens_used=tokens
                )
            else:
                return RequestResult(
                    request_id=request_id,
                    success=False,
                    status_code=response.status_code,
                    duration=duration,
                    error_message=response.text
                )
        else:
            # æµå¼è¯·æ±‚
            async with client.stream("POST", url, json=payload, headers=headers) as response:
                if response.status_code != 200:
                    duration = time.time() - start_time
                    error_text = await response.aread()
                    return RequestResult(
                        request_id=request_id,
                        success=False,
                        status_code=response.status_code,
                        duration=duration,
                        error_message=error_text.decode('utf-8')
                    )
                
                # æ¥æ”¶æµå¼æ•°æ®
                chunk_count = 0
                async for line in response.aiter_lines():
                    if not line or not line.strip():
                        continue
                    
                    line = line.strip()
                    if line.startswith("data:"):
                        chunk_str = line[5:].strip()
                        if chunk_str == "[DONE]":
                            break
                        if chunk_str:
                            chunk_count += 1
                
                duration = time.time() - start_time
                return RequestResult(
                    request_id=request_id,
                    success=True,
                    status_code=200,
                    duration=duration,
                    response_data={"chunk_count": chunk_count}
                )
    
    except asyncio.TimeoutError:
        duration = time.time() - start_time
        return RequestResult(
            request_id=request_id,
            success=False,
            status_code=None,
            duration=duration,
            error_message="è¯·æ±‚è¶…æ—¶"
        )
    except Exception as e:
        duration = time.time() - start_time
        return RequestResult(
            request_id=request_id,
            success=False,
            status_code=None,
            duration=duration,
            error_message=str(e)
        )


async def run_concurrent_requests(
    num_requests: int,
    concurrency: int,
    model: str = "glm-4.5",
    stream: bool = False,
    timeout: float = 60.0
) -> List[RequestResult]:
    """
    è¿è¡Œå¹¶å‘è¯·æ±‚
    
    Args:
        num_requests: æ€»è¯·æ±‚æ•°
        concurrency: å¹¶å‘æ•°
        model: æ¨¡å‹åç§°
        stream: æ˜¯å¦æµå¼
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        List[RequestResult]: è¯·æ±‚ç»“æœåˆ—è¡¨
    """
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œå¹¶å‘æµ‹è¯•...")
    print(f"   æ€»è¯·æ±‚æ•°: {num_requests}")
    print(f"   å¹¶å‘æ•°: {concurrency}")
    print(f"   æ¨¡å‹: {model}")
    print(f"   æ¨¡å¼: {'æµå¼' if stream else 'éæµå¼'}")
    print(f"   è¶…æ—¶æ—¶é—´: {timeout}ç§’")
    
    results = []
    
    # åˆ›å»ºå¼‚æ­¥HTTPå®¢æˆ·ç«¯
    limits = httpx.Limits(max_keepalive_connections=concurrency, max_connections=concurrency * 2)
    timeout_config = httpx.Timeout(timeout)
    
    async with httpx.AsyncClient(limits=limits, timeout=timeout_config) as client:
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        semaphore = asyncio.Semaphore(concurrency)
        
        async def limited_request(request_id: int, message_index: int):
            async with semaphore:
                return await send_single_request(
                    client, request_id, model, stream, message_index
                )
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [
            limited_request(i, i) 
            for i in range(num_requests)
        ]
        
        # æ‰§è¡Œä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
        total_start = time.time()
        
        # ä½¿ç”¨ gather æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(RequestResult(
                    request_id=i,
                    success=False,
                    status_code=None,
                    duration=0.0,
                    error_message=str(result)
                ))
            else:
                processed_results.append(result)
        
        total_duration = time.time() - total_start
        
        print(f"\nâœ… å¹¶å‘æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        return processed_results


def analyze_results(results: List[RequestResult]) -> Dict[str, Any]:
    """
    åˆ†ææµ‹è¯•ç»“æœ
    
    Args:
        results: è¯·æ±‚ç»“æœåˆ—è¡¨
    
    Returns:
        Dict: åˆ†æç»Ÿè®¡æ•°æ®
    """
    total = len(results)
    successful = sum(1 for r in results if r.success)
    failed = total - successful
    
    success_rate = (successful / total * 100) if total > 0 else 0
    
    # è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡
    durations = [r.duration for r in results if r.success]
    
    if durations:
        avg_duration = statistics.mean(durations)
        median_duration = statistics.median(durations)
        min_duration = min(durations)
        max_duration = max(durations)
        
        if len(durations) > 1:
            std_duration = statistics.stdev(durations)
        else:
            std_duration = 0.0
    else:
        avg_duration = median_duration = min_duration = max_duration = std_duration = 0.0
    
    # ç»Ÿè®¡Tokenä½¿ç”¨
    total_tokens = sum(r.tokens_used for r in results if r.tokens_used)
    
    # ç»Ÿè®¡é”™è¯¯ç±»å‹
    error_types = {}
    for r in results:
        if not r.success and r.error_message:
            error_msg = r.error_message[:50]  # æˆªå–å‰50ä¸ªå­—ç¬¦
            error_types[error_msg] = error_types.get(error_msg, 0) + 1
    
    return {
        "total_requests": total,
        "successful_requests": successful,
        "failed_requests": failed,
        "success_rate": success_rate,
        "avg_duration": avg_duration,
        "median_duration": median_duration,
        "min_duration": min_duration,
        "max_duration": max_duration,
        "std_duration": std_duration,
        "total_tokens": total_tokens,
        "error_types": error_types,
        "durations": durations
    }


def print_analysis(analysis: Dict[str, Any], test_name: str = "æµ‹è¯•"):
    """
    æ‰“å°åˆ†æç»“æœ
    
    Args:
        analysis: åˆ†ææ•°æ®
        test_name: æµ‹è¯•åç§°
    """
    print_section(f"{test_name} - ç»“æœåˆ†æ")
    
    print(f"\nğŸ“Š è¯·æ±‚ç»Ÿè®¡:")
    print(f"   æ€»è¯·æ±‚æ•°: {analysis['total_requests']}")
    print(f"   æˆåŠŸæ•°: {analysis['successful_requests']} âœ…")
    print(f"   å¤±è´¥æ•°: {analysis['failed_requests']} âŒ")
    print(f"   æˆåŠŸç‡: {analysis['success_rate']:.2f}%")
    
    print(f"\nâ±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡:")
    print(f"   å¹³å‡å“åº”æ—¶é—´: {analysis['avg_duration']:.3f}ç§’")
    print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {analysis['median_duration']:.3f}ç§’")
    print(f"   æœ€å¿«å“åº”: {analysis['min_duration']:.3f}ç§’")
    print(f"   æœ€æ…¢å“åº”: {analysis['max_duration']:.3f}ç§’")
    print(f"   æ ‡å‡†å·®: {analysis['std_duration']:.3f}ç§’")
    
    if analysis['total_tokens'] > 0:
        print(f"\nğŸ”¢ Tokenä½¿ç”¨ç»Ÿè®¡:")
        print(f"   æ€»Tokenæ•°: {analysis['total_tokens']}")
        print(f"   å¹³å‡æ¯è¯·æ±‚: {analysis['total_tokens'] / analysis['successful_requests']:.0f}") if analysis['successful_requests'] > 0 else None
    
    if analysis['error_types']:
        print(f"\nâŒ é”™è¯¯ç±»å‹ç»Ÿè®¡:")
        for error, count in sorted(analysis['error_types'].items(), key=lambda x: x[1], reverse=True):
            print(f"   [{count}æ¬¡] {error}")
    
    # è®¡ç®—ååé‡
    if analysis['durations']:
        total_time = max(analysis['durations'])
        throughput = analysis['successful_requests'] / total_time if total_time > 0 else 0
        print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   ååé‡: {throughput:.2f} è¯·æ±‚/ç§’")


def print_percentiles(durations: List[float]):
    """
    æ‰“å°å“åº”æ—¶é—´ç™¾åˆ†ä½æ•°
    
    Args:
        durations: å“åº”æ—¶é—´åˆ—è¡¨
    """
    if not durations:
        return
    
    sorted_durations = sorted(durations)
    percentiles = [50, 75, 90, 95, 99]
    
    print(f"\nğŸ“Š å“åº”æ—¶é—´ç™¾åˆ†ä½æ•°:")
    for p in percentiles:
        index = int(len(sorted_durations) * p / 100)
        if index >= len(sorted_durations):
            index = len(sorted_durations) - 1
        value = sorted_durations[index]
        print(f"   P{p}: {value:.3f}ç§’")


async def test_basic_concurrency():
    """åŸºç¡€å¹¶å‘æµ‹è¯•"""
    print_section("åŸºç¡€å¹¶å‘æµ‹è¯• - éæµå¼")
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {"num_requests": 5, "concurrency": 1, "name": "é¡ºåºæ‰§è¡Œ (1å¹¶å‘, 5è¯·æ±‚)"},
        {"num_requests": 10, "concurrency": 5, "name": "ä½å¹¶å‘ (5å¹¶å‘, 10è¯·æ±‚)"},
        {"num_requests": 20, "concurrency": 10, "name": "ä¸­å¹¶å‘ (10å¹¶å‘, 20è¯·æ±‚)"},
    ]
    
    all_results = []
    
    for config in test_configs:
        print(f"\n{'â”€' * 100}")
        print(f"ğŸ§ª æµ‹è¯•åœºæ™¯: {config['name']}")
        
        results = await run_concurrent_requests(
            num_requests=config['num_requests'],
            concurrency=config['concurrency'],
            stream=False
        )
        
        analysis = analyze_results(results)
        print_analysis(analysis, config['name'])
        print_percentiles(analysis['durations'])
        
        all_results.append({
            "config": config,
            "analysis": analysis
        })
        
        # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡è½½
        await asyncio.sleep(1)
    
    return all_results


async def test_stream_concurrency():
    """æµå¼è¯·æ±‚å¹¶å‘æµ‹è¯•"""
    print_section("æµå¼è¯·æ±‚å¹¶å‘æµ‹è¯•")
    
    results = await run_concurrent_requests(
        num_requests=10,
        concurrency=5,
        stream=True
    )
    
    analysis = analyze_results(results)
    print_analysis(analysis, "æµå¼è¯·æ±‚å¹¶å‘æµ‹è¯•")
    print_percentiles(analysis['durations'])
    
    return analysis


async def test_stress():
    """å‹åŠ›æµ‹è¯•"""
    print_section("å‹åŠ›æµ‹è¯•")
    
    print("\nâš ï¸  è­¦å‘Š: è¿™å°†å‘é€å¤§é‡å¹¶å‘è¯·æ±‚ï¼Œè¯·ç¡®ä¿æœåŠ¡å™¨èƒ½å¤Ÿæ‰¿å—ï¼")
    print("   æŒ‰ Ctrl+C å¯ä»¥éšæ—¶ä¸­æ–­æµ‹è¯•...")
    
    await asyncio.sleep(2)
    
    # å‹åŠ›æµ‹è¯•é…ç½®
    results = await run_concurrent_requests(
        num_requests=50,
        concurrency=20,
        stream=False,
        timeout=120.0
    )
    
    analysis = analyze_results(results)
    print_analysis(analysis, "å‹åŠ›æµ‹è¯•")
    print_percentiles(analysis['durations'])
    
    return analysis


async def test_health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{API_BASE_URL}/health")
            return response.status_code == 200
    except Exception:
        return False


def print_summary(all_tests: List[Dict[str, Any]]):
    """æ‰“å°æ€»ç»“"""
    print_section("æµ‹è¯•æ€»ç»“")
    
    print("\nğŸ“‹ æ‰€æœ‰æµ‹è¯•åœºæ™¯å¯¹æ¯”:\n")
    print(f"{'æµ‹è¯•åœºæ™¯':<40} {'æˆåŠŸç‡':<12} {'å¹³å‡å“åº”':<12} {'ååé‡':<12}")
    print("â”€" * 100)
    
    for test in all_tests:
        if 'config' in test:
            name = test['config']['name']
            analysis = test['analysis']
        else:
            name = test.get('name', 'æœªçŸ¥æµ‹è¯•')
            analysis = test['analysis']
        
        success_rate = f"{analysis['success_rate']:.2f}%"
        avg_duration = f"{analysis['avg_duration']:.3f}ç§’"
        
        if analysis['durations']:
            total_time = max(analysis['durations'])
            throughput = analysis['successful_requests'] / total_time if total_time > 0 else 0
            throughput_str = f"{throughput:.2f} req/s"
        else:
            throughput_str = "N/A"
        
        print(f"{name:<40} {success_rate:<12} {avg_duration:<12} {throughput_str:<12}")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 100)
    print(" OpenAI å…¼å®¹ API æœåŠ¡å™¨ - å¹¶å‘æ€§èƒ½æµ‹è¯• ".center(100))
    print("=" * 100)
    print(f"\nâ° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å¥åº·æ£€æŸ¥
    print("\nğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    if not await test_health_check():
        print("âŒ æœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è®¿é—®ï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡ï¼")
        sys.exit(1)
    print("âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
    
    all_tests = []
    
    try:
        # 1. åŸºç¡€å¹¶å‘æµ‹è¯•
        basic_results = await test_basic_concurrency()
        all_tests.extend(basic_results)
        
        # 2. æµå¼è¯·æ±‚æµ‹è¯•
        stream_analysis = await test_stream_concurrency()
        all_tests.append({"name": "æµå¼è¯·æ±‚å¹¶å‘æµ‹è¯•", "analysis": stream_analysis})
        
        # 3. å‹åŠ›æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
        print("\n" + "â”€" * 100)
        user_input = input("\næ˜¯å¦æ‰§è¡Œå‹åŠ›æµ‹è¯•? (y/N): ").strip().lower()
        if user_input == 'y':
            stress_analysis = await test_stress()
            all_tests.append({"name": "å‹åŠ›æµ‹è¯•", "analysis": stress_analysis})
        else:
            print("â­ï¸  è·³è¿‡å‹åŠ›æµ‹è¯•")
        
        # æ‰“å°æ€»ç»“
        print_summary(all_tests)
        
        print(f"\nâ° æµ‹è¯•ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. è§‚å¯Ÿä¸åŒå¹¶å‘çº§åˆ«ä¸‹çš„æ€§èƒ½å˜åŒ–")
        print("   2. å…³æ³¨æˆåŠŸç‡ï¼Œç¡®ä¿æœåŠ¡ç¨³å®šæ€§")
        print("   3. ç›‘æ§å“åº”æ—¶é—´çš„åˆ†å¸ƒæƒ…å†µ")
        print("   4. æŸ¥çœ‹æœåŠ¡å™¨èµ„æºä½¿ç”¨æƒ…å†µï¼ˆCPUã€å†…å­˜ã€ç½‘ç»œï¼‰")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())









